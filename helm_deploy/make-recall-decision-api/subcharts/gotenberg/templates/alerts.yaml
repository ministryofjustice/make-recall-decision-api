{{- $targetNamespace := .Release.Namespace }}
---
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: {{ template "app.fullname" . }}
  labels:
    {{- include "app.labels" . | nindent 4 }}
spec:
  groups:
    - name: {{ template "app.fullname" . }}
      rules:
        - alert: KubePodCrashLooping
          annotations:
            message: Pod {{`{{`}} $labels.namespace {{`}}`}}/{{`{{`}} $labels.pod {{`}}`}} ({{`{{`}} $labels.container {{`}}`}}) is restarting {{`{{`}} printf "%.2f" $value {{`}}`}} times every 5 minutes.
            runbook_url: {{ .Values.runbookUrl }}application-pod-crashlooping
            dashboard_url: {{ $.Values.grafanaUrl }}/d/application-alerts/application-alerts?orgId=1&var-namespace={{ $targetNamespace }}
            summary: Pod is crash looping.
          expr: |
            rate(kube_pod_container_status_restarts_total{job="kube-state-metrics", namespace="{{ $targetNamespace }}", pod=~"{{ include "app.podregex" . }}"}[10m]) * 60 * 5 > 0
          for: 15m
          labels:
            severity: {{ .Values.alertSeverity }}

        - alert: KubePodNotReady
          annotations:
            message: Pod {{`{{`}} $labels.namespace {{`}}`}}/{{`{{`}} $labels.pod {{`}}`}} has been in a non-ready state for longer than 15 minutes.
            runbook_url: {{ .Values.runbookUrl }}application-pod-notready
            dashboard_url: {{ $.Values.grafanaUrl }}/d/application-alerts/application-alerts?orgId=1&var-namespace={{ $targetNamespace }}
            summary: Pod has been in a non-ready state for more than 15 minutes.
          expr: sum by (namespace, pod) (kube_pod_status_phase{job="kube-state-metrics", namespace="{{ $targetNamespace }}", pod=~"{{ include "app.podregex" . }}", phase=~"Pending|Unknown"}) > 0
          for: 15m
          labels:
            severity: {{ .Values.alertSeverity }}

        - alert: KubeDeploymentGenerationMismatch
          annotations:
            message: Deployment generation for {{`{{`}} $labels.namespace {{`}}`}}/{{`{{`}} $labels.deployment {{`}}`}} does not match, this indicates that the Deployment has failed but has not been rolled back.
            runbook_url: {{ .Values.runbookUrl }}application-deployment-generation-mismatch
            dashboard_url: {{ $.Values.grafanaUrl }}/d/application-alerts/application-alerts?orgId=1&var-namespace={{ $targetNamespace }}
            summary: Deployment generation mismatch due to possible roll-back
          expr: |-
            kube_deployment_status_observed_generation{job="kube-state-metrics", namespace="{{ $targetNamespace }}", deployment="{{ include "app.fullname" . }}"}
              !=
            kube_deployment_metadata_generation{job="kube-state-metrics", namespace="{{ $targetNamespace }}", deployment="{{ include "app.fullname" . }}"}
          for: 15m
          labels:
            severity: {{ .Values.alertSeverity }}

        - alert: KubeDeploymentReplicasMismatch
          annotations:
            message: Deployment {{`{{`}} $labels.namespace {{`}}`}}/{{`{{`}} $labels.deployment {{`}}`}} has not matched the expected number of replicas for longer 15 minutes.
            runbook_url: {{ .Values.runbookUrl }}application-deployment-replicas-mismatch
            dashboard_url: {{ $.Values.grafanaUrl }}/d/application-alerts/application-alerts?orgId=1&var-namespace={{ $targetNamespace }}
            summary: Deployment has not matched the expected number of replicas.
          expr: |-
            kube_deployment_spec_replicas{job="kube-state-metrics", namespace="{{ $targetNamespace }}", deployment="{{ include "app.fullname" . }}"}
              !=
            kube_deployment_status_replicas_available{job="kube-state-metrics", namespace="{{ $targetNamespace }}", deployment="{{ include "app.fullname" . }}"}
          for: 15m
          labels:
            severity: {{ .Values.alertSeverity }}

        - alert: KubeContainerWaiting
          annotations:
            description: Pod {{`{{`}} $labels.namespace {{`}}`}}/{{`{{`}} $labels.pod {{`}}`}} container {{`{{`}} $labels.container {{`}}`}} has been in waiting state for longer than 1 hour.
            runbook_url: {{ .Values.runbookUrl }}application-container-waiting
            dashboard_url: {{ $.Values.grafanaUrl }}/d/application-alerts/application-alerts?orgId=1&var-namespace={{ $targetNamespace }}
            summary: Pod container waiting longer than 1 hour
          expr: |
            sum by (namespace, pod, container) (kube_pod_container_status_waiting_reason{job="kube-state-metrics", namespace="{{ $targetNamespace }}", pod=~"{{ include "app.podregex" . }}"}) > 0
          for: 1h
          labels:
            severity: {{ .Values.alertSeverity }}

        - alert: KubeContainerOOMKilled
          annotations:
            message: "Container {{`{{`}} $labels.container {{`}}`}} in pod {{`{{`}} $labels.namespace {{`}}`}}/{{`{{`}} $labels.pod {{`}}`}} has been OOM Killed (out of memory) {{`{{`}} $value {{`}}`}} times in the last 10 minutes."
            runbook_url: {{ .Values.runbookUrl }}application-container-oom-killed
            dashboard_url: {{ $.Values.grafanaUrl }}/d/application-alerts/application-alerts?orgId=1&var-namespace={{ $targetNamespace }}
            summary: Kubernetes container OOM killed (instance {{`{{`}} $labels.instance {{`}}`}})
          expr: |-
            (kube_pod_container_status_restarts_total{job="kube-state-metrics", namespace="{{ $targetNamespace }}", pod=~"{{ include "app.podregex" . }}"}
             - kube_pod_container_status_restarts_total{job="kube-state-metrics", namespace="{{ $targetNamespace }}", pod=~"{{ include "app.podregex" . }}"} offset 10m >= 1)
              and ignoring (reason) min_over_time(kube_pod_container_status_last_terminated_reason{job="kube-state-metrics", namespace="{{ $targetNamespace }}", pod=~"{{ include "app.podregex" . }}", reason="OOMKilled"}[10m]) == 1
          for: 0m
          labels:
            severity: {{ .Values.alertSeverity }}
